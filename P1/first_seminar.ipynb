{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\junio\\documents\\4to\\sistemas de codificación de audio y vídeo\\video\\practicas\\videopractices\\.venv\\lib\\site-packages (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: ffmpeg-python in c:\\users\\junio\\documents\\4to\\sistemas de codificación de audio y vídeo\\video\\practicas\\videopractices\\.venv\\lib\\site-packages (0.2.0)\n",
      "Requirement already satisfied: future in c:\\users\\junio\\documents\\4to\\sistemas de codificación de audio y vídeo\\video\\practicas\\videopractices\\.venv\\lib\\site-packages (from ffmpeg-python) (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#If packages not installed\n",
    "'''\n",
    "%pip install numpy\n",
    "%pip install ffmpeg-python\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ffmpeg\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Image:\n",
    "\n",
    "    y = 0\n",
    "    u = 0\n",
    "    v = 0\n",
    "\n",
    "    def __init__(self, r, g, b):\n",
    "        self.r = r\n",
    "        self.g = g\n",
    "        self.b = b\n",
    "\n",
    "    def rgb_to_yuv(self):\n",
    "        self.y = (0.257 * self.r) + (0.504 * self.g) + (0.098 * self.b) + 16\n",
    "        self.u = (-0.148 * self.r) - (0.291 * self.g) + (0.439 * self.b) + 128\n",
    "        self.v = (0.439 * self.r) - (0.368 * self.g) - (0.071 * self.b) + 128\n",
    "    \n",
    "    def yuv_to_rgb(self):\n",
    "        self.b = 1.164 * (self.y - 16) + 2.018 * (self.u - 128)\n",
    "        self.g = 1.164 * (self.y - 16) - 0.813 * (self.v - 128) - 0.391 * (self.u - 128)\n",
    "        self.r = 1.164 * (self.y - 16) + 1.596 * (self.v - 128) \n",
    "    \n",
    "    def print_RGB_values(self):\n",
    "        print(\"R:\", self.r, \"\\n\")\n",
    "        print(\"G:\", self.g, \"\\n\")\n",
    "        print(\"B:\", self.b, \"\\n\")\n",
    "\n",
    "    def print_YUV_values(self):\n",
    "        print(\"Y:\", self.y, \"\\n\")\n",
    "        print(\"U:\", self.u, \"\\n\")\n",
    "        print(\"V:\", self.v, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R: 100 \n",
      "\n",
      "G: 50 \n",
      "\n",
      "B: 255 \n",
      "\n",
      "Y: 91.89 \n",
      "\n",
      "U: 210.59500000000003 \n",
      "\n",
      "V: 135.395 \n",
      "\n",
      "R: 100.13838000000001 \n",
      "\n",
      "G: 50.02917999999999 \n",
      "\n",
      "B: 255.01267000000004 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Exercise 2\n",
    "i1 = Image(100, 50, 255)\n",
    "i1.print_RGB_values()\n",
    "i1.rgb_to_yuv()\n",
    "i1.print_YUV_values()\n",
    "i1.yuv_to_rgb()\n",
    "i1.print_RGB_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#Exercise 3\n",
    "image = ffmpeg.input('image.jpg')\n",
    "resize_image = image.output(image, 'output.jpg')\n",
    "ffmpeg.run(image)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exercise 4\n",
    "#Code taken from (https://stackoverflow.com/questions/57366966/serpentine-scan-pattern-generator)\n",
    "def zigzag(dims):\n",
    "    r = np.arange(np.prod(dims))\n",
    "    out = []\n",
    "    for d in dims:\n",
    "        out.append(np.abs((1|((d+r)<<1))%(d<<2)-(d<<1))>>1)\n",
    "        r //= d\n",
    "    return np.transpose(out[::-1])\n",
    "###\n",
    "\n",
    "path = 'coltrane.jpg'\n",
    "coltrane = ffmpeg.input(path)\n",
    "\n",
    "probe = ffmpeg.probe(path)\n",
    "\n",
    "image_info = next(s for s in probe['streams'] if s['codec_type'] == 'video')\n",
    "\n",
    "width = int(image_info['width'])\n",
    "height = int(image_info['height'])\n",
    "\n",
    "out, err = (\n",
    "    ffmpeg\n",
    "    .input(path)\n",
    "    .output('pipe:', format='rawvideo', pix_fmt='rgb24')\n",
    "    .run(capture_stdout=True)\n",
    ")\n",
    "\n",
    "coltrane_array = (\n",
    "    np\n",
    "    .frombuffer(out, np.uint8)\n",
    "    .reshape([-1, height, width, 3])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
